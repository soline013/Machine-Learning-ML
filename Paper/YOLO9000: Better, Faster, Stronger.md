# YOLO9000: Better, Faster, Stronger

[YOLO9000: Better, Faster, Stronger](https://arxiv.org/pdf/1612.08242.pdf)

![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/Computer_Vision_Timeline.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/Computer_Vision_Timeline.png)

## Abstract.

- ðŸ–¼ï¸ Figure 1.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_6.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_6.png)

- Real-time Object Detection System.

    Detect Over 9000 Object Categories.

- Standard Detection Tasks Like PASCAL VOC & COCO.

    Outperforming Faster R-CNN With ResNet & SSD.

- Jointly Train on Object Detection & Classification.

    COCO Detection Dataset & ImageNet Classification Dataset.

## Introduction.

1. Neural Networksì˜ ë“±ìž¥ìœ¼ë¡œ, Object Detectionì€ ë¹ ë¥´ê³  ì •í™•í•´ì¡Œë‹¤.

    ê·¸ëŸ¬ë‚˜ Classification, Tagging ë“±ê³¼ ë¹„êµí–ˆì„ ë•Œ, Datasetì´ ë„ˆë¬´ ìž‘ë‹¤ëŠ” ë¬¸ì œê°€ ìžˆë‹¤.

2. Classification ìˆ˜ì¤€ì—ì„œ Detectionì„ í•˜ê³  ì‹¶ì§€ë§Œ, Detectionì„ ìœ„í•œ Labelingì€ ì–´ë µë‹¤.

    ë”°ë¼ì„œ Classification Datasetì„ í™œìš©í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ì œì•ˆë˜ì—ˆë‹¤.

    1. Hierarchical View of Object Classification.

        Combine distinct datasets together(Classification Dataset, Detcetion Dataset).

    2. Joint Training Algorithm.

        Leverages labeled detection images to learn to precisely localize objects.

        Leverages classification images to increase its vocabulary and robustness.

3. YOLOë¥¼ ê°œì„ í•œ YOLOv2ë¥¼ ì œì•ˆí•˜ê³ , ìœ„ì˜ ë‘ ë°©ë²•ì„ ì ìš©í•œ YOLO9000ì„ ì œì•ˆí–ˆë‹¤.

## Better.

- ê¸°ì¡´ YOLOì˜ ë‹¨ì .
    - YOLOëŠ” Fast R-CNNê³¼ ë¹„êµí–ˆì„ ë•Œ, ì¤‘ìš”í•œ Localization Errorê°€ ë°œìƒí•œë‹¤.
    - Region Proposal ê¸°ë°˜ì˜ ë°©ì‹ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ, Recallì´ ë‚®ë‹¤.
    - Localization Errorì™€ Recallì„ ìž¡ìœ¼ë©´ì„œ, Classification Accuracyë¥¼ ìœ ì§€í•˜ëŠ”ë° ì§‘ì¤‘í•œë‹¤.

- Batch Normalization.

    Dropoutì„ ì œê±°í•˜ê³  Batch Normalizationì„ ì¶”ê°€í•˜ì˜€ê³ , mAPê°€ 2% ì¦ê°€í–ˆë‹¤.

    - ë²ˆì™¸. mAP.

        Mutiple Object Detection ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ì„±ëŠ¥ì„ 1ê°œì˜ Scalar Valueë¡œ í‘œí˜„í•œ ê²ƒì´ë‹¤.

        [[Deep Learning] mAP (Mean Average Precision) ì •ë¦¬](https://eehoeskrap.tistory.com/m/237)

- High Resolution Classifier.
    1. State-of-the-art Detectionì€ ImageNet ê¸°ë°˜ì˜ Classifier Pre-trained Networkë¥¼ ì‚¬ìš©í•œë‹¤. ì—¬ê¸°ì„œ ëŒ€ë¶€ë¶„ì˜ ìž…ë ¥ì€ 256X256 ë³´ë‹¤ ìž‘ë‹¤.
    2. ê¸°ì¡´ YOLOëŠ” 224X224 í¬ê¸°ì˜ Classifier Pre-trained Networkë¥¼ ì‚¬ìš©í•˜ë©°, 448X448 í¬ê¸°ë¡œ ì¦ê°€ì‹œì¼œ ì‚¬ìš©í–ˆë‹¤.
    3. YOLOv2ëŠ” 448X448 í¬ê¸°ë¡œ ImageNetì—ì„œ 10 Epochsë¥¼ ìˆ˜í–‰í•˜ì˜€ê³ , mAPê°€ 4% ì¦ê°€í–ˆë‹¤.

- Convolutional With Anchor Boxes.
    1. YOLOëŠ” Bounding Boxesì˜ Coordinatesë¥¼ FC Layerë¡œ ì§ì ‘ ì˜ˆì¸¡í•œë‹¤.
    2. FC Layerë¥¼ ì‚­ì œí•˜ê³  Convolutional Layerë¡œ ë°”ê¾¸ì—ˆê³ , Anchor Boxë¥¼ ì‚¬ìš©í•´ì„œ Boxì˜ Offsetì„ ì˜ˆì¸¡í•œë‹¤.
    3. Conv Layer ì¶œë ¥ì˜ í•´ìƒë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ Pooling Layer í•˜ë‚˜ë¥¼ ì œê±°í•œë‹¤.
    4. 448X448 í¬ê¸°ë¥¼ 416X416ìœ¼ë¡œ ë³€ê²½í•˜ì—¬, ìµœì¢… Feature Mapì—ì„œ Width, Heightê°€ í™€ìˆ˜ê°€ ëœë‹¤. ë³´í†µ í° ì´ë¯¸ì§€ëŠ” ê°€ìš´ë° Cellì´ ìžˆëŠ”ë°, ì´ë•Œ í™€ìˆ˜ë¼ë©´ ê°€ìš´ë°ì— Single Cell ìƒì„±ë˜ì–´ ë” ì¢‹ì€ ì„±ëŠ¥ì´ ë‚œë‹¤.
    5. YOLOv2ì˜ Downsample FactorëŠ” 32ì´ê³ (2X2 Max Pooling$^5$), ìµœì¢… Feature Mapì˜ í¬ê¸°ëŠ” 13X13ì´ë‹¤.
    6. ê¸°ì¡´ YOLOëŠ” Grid ê¸°ë°˜ìœ¼ë¡œ Classë¥¼ ì˜ˆì¸¡í•˜ì˜€ìœ¼ë‚˜, YOLOv2ëŠ”  Anchor Box ê¸°ë°˜ì´ë‹¤.
    7. ê¸°ì¡´ YOLOê°€ ìž…ë ¥ ì´ë¯¸ì§€ ë‹¹ 98ê°œì˜ Boxë¥¼ ì˜ˆì¸¡í–ˆë‹¤ë©´, YOLv2ëŠ” Anchor Boxë¡œ ì²œ ê°œì´ìƒì˜ Boxë¥¼ ì˜ˆì¸¡í•œë‹¤.
    8. mAPëŠ” 69.5ì—ì„œ 69.2ë¡œ ê°ì†Œí–ˆì§€ë§Œ, Recallì€ 81%ì—ì„œ 88%ë¡œ ì¦ê°€í–ˆë‹¤.

- Dimension Clusters.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_2.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_2.png)

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_3.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_3.png)

    1. Anchor Boxë¥¼ ì‚¬ìš©í•˜ë©´ì„œ 2ê°€ì§€ ë¬¸ì œê°€ ìƒê²¼ëŠ”ë°, í•˜ë‚˜ëŠ” Box Dimensionì´ Hand-pick ëœë‹¤ëŠ” ê²ƒì´ë‹¤.

    2. ë”°ë¼ì„œ YOLO9000ì€ K-meanì„ ì‚¬ìš©í•˜ëŠ”ë°, Euclidian Distance ëŒ€ì‹  ì•„ëž˜ì˜ ì‹ì„ ì‚¬ìš©í•œë‹¤.

        $$d(\text{box, centroid}) = 1 - \text{IOU(box, centroid)}$$

        > ... larger boxes generate more error than smaller boxes. ... we really want are priors that lead to good IOU scores, which is independent of the size of the box.

    3. K-meanì€ Parameter $K$ì˜ ê°’ì´ ì¤‘ìš”í•œë°, ë…¼ë¬¸ì—ì„œëŠ” $K=5$ë¡œ ì„¤ì •í•˜ì˜€ë‹¤.

        ì„±ëŠ¥ê³¼ ì—°ì‚°ì†ë„ëŠ” Trade-off ê´€ê³„ì— ìžˆì–´ ì ë‹¹í•œ ê°’ì´ ì¤‘ìš”í•˜ê³ , ì„±ëŠ¥ ì¦ê°€ì—ë„ í•œê³„ê°€ ìžˆë‹¤.

    4. Cluster SSE(Error Sum of Squares, Euclidian Distance), Cluster IOU(Intersection Over Union), Anchor Boxes(Hand-pick)ë¥¼ ë¹„êµí–ˆì„ ë•Œ, $K=5$ì¸ Cluster IOUë¥¼ ì„ íƒí•˜ì˜€ë‹¤.

    - ë²ˆì™¸. IOU(Intersection Over Union).

        ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/IOU.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/IOU.png)

        ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/IOU_2.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/IOU_2.png)

        [IoU, Intersection over Union ê°œë…ì„ ì´í•´í•˜ìž](https://ballentain.tistory.com/12)

- Direct Location Prediction.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_4.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_4.png)

    1. Anchor Boxë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ìƒê¸´ ë‘ ë²ˆì§¸ ë¬¸ì œëŠ” ëª¨ë¸ì´ ë¶ˆì•ˆì •í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤.

    2. ë¶ˆì•ˆì •ì„±ì€ Boxì˜ (x, y) ì¢Œí‘œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì—ì„œ ì¼ì–´ë‚˜ëŠ”ë°, ì•„ëž˜ ì‹ì„ í†µí•´ ê³„ì‚°í•  ìˆ˜ ìžˆë‹¤.

        $$x = (t_x * w_a) - x_a \\ y = (t_y * h_a) - y_a$$

        $t_x$ê°€ ì–‘ìˆ˜ë¼ë©´ ì˜¤ë¥¸ìª½, ìŒìˆ˜ë¼ë©´ ì™¼ìª½ìœ¼ë¡œ ì›€ì§ì´ê²Œ ë˜ëŠ”ë°, ì œí•œì´ ì—†ìœ¼ë¯€ë¡œ Random Initializationì—ì„œ ì•ˆì •ì ì¸ Offset ê°’ê¹Œì§€ ì˜¤ëžœ ì‹œê°„ì´ ê±¸ë¦°ë‹¤.

    3. YOLO9000ì€ Offsetì˜ ë²”ìœ„ë¥¼ [0, 1]ë¡œ ì œí•œí•˜ê³ , Logistic Activationì„ ì‚¬ìš©í•œë‹¤.

        $$b_x = \sigma(t_x) + c_x \\ b_y = \sigma(t_y) + c_y \\ b_w = p_we^{t_w} \\ b_h = p_he^{t_h} \\ Pr(\text{object}) * IOU(\text{b, object}) = \sigma(t_o)$$

        $t_x, \, t_y, \, t_w, \, t_h, \, t_o$ : Bounding Boxì˜ ìš”ì†Œ.

        $(c_x, \, c_y)$ : Cellì˜ ì™¼ìª½ ìƒë‹¨ Offset.

        $(p_w, \, p_h)$ : Anchor Boxì˜ ì‚¬ì „ Width, Height.

        NetworkëŠ” ê° Cell ë§ˆë‹¤ 5ê°œì˜ Bounding Boxë¥¼ ì˜ˆì¸¡í•œë‹¤.

    4. Dimension Clusterì™€ Direct Location Predictionì„ í†µí•´ 5%ì˜ ì„±ëŠ¥ í–¥ìƒì´ ì¼ì–´ë‚¨.

- Fine-Grained Features.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_0.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_0.png)

    1. ê¸°ì¡´ YOLOëŠ” 13X13 Feature Mapìœ¼ë¡œ, í° ì´ë¯¸ì§€ë¥¼ ê²€ì¶œí•˜ê¸°ì—ëŠ” ì¶©ë¶„í•˜ì§€ë§Œ ìž‘ì€ ì´ë¯¸ì§€ì—ëŠ” ë¶ˆì¶©ë¶„í•˜ë‹¤.
    2. ì´ì „ Layerì—ì„œ 26X26 Feature Mapì„ ê°€ì ¸ì™€ 26X26X512 í¬ê¸°ë¥¼ 13X13X2048ë¡œ Rescale í•œë‹¤.
    3. ê¸°ì¡´ 13X13 Feature Mapê³¼ Concatí•œ Passthrough Layerë¥¼ ë§Œë“ ë‹¤.
    4. ì—¬ê¸°ì„œ Concatì€ ë‹¤ë¥¸ ì±„ë„ì— Stackí•˜ëŠ” ê²ƒìœ¼ë¡œ, ResNetì˜ Identity Mappingsê³¼ ë¹„ìŠ·í•˜ë‹¤.
    5. 1%ì˜ ì„±ëŠ¥ í–¥ìƒì´ ì¼ì–´ë‚œë‹¤.

- Multi-Scale Training.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_5.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_5.png)

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_6%201.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_6%201.png)

    1. YOLOv2ëŠ” FC Layerë¥¼ ì œê±°í•˜ì—¬ ì—¬ëŸ¬ Sizeì˜ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•  ìˆ˜ ìžˆê³ , ì‹¤í–‰ì— ì˜®ê²¼ë‹¤.
    2. {320, 352, ..., 608}ì²˜ëŸ¼ 32 Pixel ê°„ê²©ìœ¼ë¡œ 10 Batchë§ˆë‹¤ ìž…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ë°”ê¾¼ë‹¤.
    3. ë‹¤ì–‘í•œ í¬ê¸°ì— ëŒ€í•´ ê°•í•´ì§€ë¯€ë¡œ Speedì™€ Accuracy ì‚¬ì´ì—ì„œ ì‰½ê²Œ Trade-offë¥¼ ì „í™˜í•  ìˆ˜ ìžˆë‹¤.
    4. 288X288ì—ì„œëŠ” 90 FPSë¡œ Fast R-CNN ì •ë„ì˜ mAPë¥¼ ê°–ê³ , 608X608ì—ì„œëŠ” VOC2007ì—ì„œ 78.6mAPë¥¼ ê°–ëŠ”ë‹¤.

- Further Experiments.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_8.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_8.png)

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_9.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_9.png)

- A Summary of Results.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_7.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_7.png)

## Faster.

- ê¸°ì¡´ YOLO.
    - ë§Žì€ Detection FrameworksëŠ” VGG-16ì„ ì‚¬ìš©í•œë‹¤. ê·¸ëŸ¬ë‚˜ VGG-16ì€ 224X244 í¬ê¸°ì˜ ê²½ìš° 30.69 Billionì˜ Floating Point ê³„ì‚°ì´ í•„ìš”í•˜ë‹¤.
    - YOLOëŠ” GoogleNet ê¸°ë°˜ì˜ ë…ìžì ì¸ Networkë¥¼ ë§Œë“¤ì–´ ë” ë¹ ë¥´ê³  ê³„ì‚°ëŸ‰ì„ 8.52 Billionìœ¼ë¡œ ì¤„ì˜€ë‹¤.
    - ê°™ì€ 224X224 í¬ê¸°ì—ì„œ AccuracyëŠ” 88%ë¡œ VGG-16ì˜ 90%ì™€ ë¹„êµí•˜ë©´ í° ì°¨ì´ê°€ ì—†ë‹¤.

- Darknet-19.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_10.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_10.png)

    YOLOv2ëŠ” Darknetì´ë¼ëŠ” ìƒˆë¡œìš´ Modelì„ ì‚¬ìš©í•œë‹¤.

    1. VGGì™€ ë¹„ìŠ·í•˜ê²Œ 3X3 Filterë¥¼ ì‚¬ìš©í•œë‹¤.
    2. Network In Networkë¥¼ ë”°ë¼ Global Average Poolingì„ ì‚¬ìš©í•œë‹¤.
    3. 1X1 Convolution Layerë¥¼ ì‚¬ìš©í•œë‹¤.
    4. 19ê°œì˜ Convolution Layerì™€ 5ê°œì˜ Pooling Layerë¥¼ ì‚¬ìš©í•œë‹¤.

    > Darknet-19 only requires 5.58 billion operations to process an image yet achieves 72.9% top-1 accuracy and 91.2% top-5 accuracy on ImageNet.

- Training for Classification.
    1. ImageNet 1000 Class Classification Dataset for 160 Epochs.
    2. SGD With Learning Rate of 0.1.
    3. Polynomial Rate Decay of 4.

        [Learning rate Schedules](https://kiranscaria.github.io/general/2019/08/16/learning-rate-schedules.html)

    4. Weight Decay of 0.005.
    5. Momemtem of 0.9.
    6. Standard Data Augmentation Tricks: Random crops, Rotations, Hue, Saturation, and Exposure Shifts.

        [CNNs in Practice](https://nmhkahn.github.io/CNN-Practice)

- Training for Detection.
    1. Adding on three 3X3 convolutional layers with 1024 filters each followed by a final 1X1 convolutional layer.
    2. For VOC we predict 5 boxes with 5 coordinates each and 20 classes per box so 125 filters. $5 \times (5 +20) =125$
    3. ìœ„ì—ì„œ ì´ë¯¸ ì–¸ê¸‰ëœ Passthrough Layer.
    4. Train the network for 160 epochs with a starting learning rate of $10^{-3}$, dividing it by 10 at 60 and 90 epochs.
    5. ìœ„ì—ì„œ ì´ë¯¸ ì–¸ê¸‰ëœ Weight Decay & Momentum.
    6. ìœ„ì—ì„œ ì´ë¯¸ ì–¸ê¸‰ëœ Data Augmentation.
    7. Use the same training strategy on COCO and VOC.

## Stronger.

- How to do Joint Training?
    - Detection Datasetì˜ ClassëŠ” "dog", "boat"ì²˜ëŸ¼ ì¼ë°˜ì ì´ë‹¤.
    - Classification Datasetì˜ ClassëŠ” "Norfolk terrier", "Yorkshire terrier", â€œBedlington terrierâ€ì²˜ëŸ¼ ì„¸ë¶€ì ì´ë‹¤.
    - Classificationì€ Softmaxë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ê° Classê°€ ë…ë¦½ì´ë¼ëŠ” ê°€ì •ì´ ìžˆë‹¤. ê·¸ëŸ¬ë‚˜ Datasetì„ í•©ì¹˜ë©´ ë…ë¦½ì´ë¼ëŠ” ê°€ì •ì´ ë¬´ë„ˆì§„ë‹¤.
    - ë”°ë¼ì„œ Datasetì€ ë…ë¦½ì´ ì•„ë‹ˆë¼ê³  ê°€ì •í•˜ê³ , Multi-label Modelì„ ì‚¬ìš©í•œë‹¤.

- Hierarchical Classification.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_11.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_11.png)

    ImageNetì˜ Labelì€ WordNet Language Datasetìœ¼ë¡œë¶€í„° íŒŒìƒë˜ì—ˆë‹¤.

    WordNetì€ Treeê°€ ì•„ë‹Œ Direct Graphì¸ë°, ì–¸ì–´ë¥¼ ê³„ì¸µì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì´ë‹¤.

    YOLO9000ì€ WordTreeë¥¼ ë§Œë“¤ì—ˆëŠ”ë°, Softmaxë¥¼ ì—†ì• ì§€ ì•Šê³  WordTree ë‚´ì—ì„œ ë…ë¦½ì ì¸ ë¶€ë¶„ì€ Softmaxë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ Softmaxë¥¼ ë³¼ ìˆ˜ ìžˆë‹¤.

- Dataset Combination With WordTree.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_12.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_12.png)

    YOLO9000ì˜ WordTreeëŠ” COCO Datasetê³¼ ImageNet Datasetì„ ëª¨ë‘ ì‚¬ìš©í–ˆë‹¤.

    WordTree 1Kë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì¤‘ê°„ì— Nodeë¥¼ ì¶”ê°€í•˜ì˜€ê³ , Labelì´ 1369ê°œë¡œ ëŠ˜ì–´ë‚¬ë‹¤.

    ---

    $$Pr(\text{Norfolk terrier}) = Pr(\text{Norfolk terrier | terrier}) \\ *Pr(\text{terrier | hunting dog}) \\ * ... * \\ Pr(\text{mammal | Pr(\text{animal})}) \\ *Pr(\text{animal | physical object})$$

    For classification purposes we assume that the the image contains an object: $Pr(\text{physical object}) = 1$.

    1. íŠ¹ì • Nodeë¥¼ ì˜ˆì¸¡í•  ë•ŒëŠ” ì¡°ê±´ë¶€ í™•ë¥ ì„ ì‚¬ìš©í•œë‹¤.
    2. í•™ìŠµì—ì„œëŠ” ì‹¤ì œ(Ground Truth) Labelë¶€í„° Lootê¹Œì§€ ëª¨ë“  ìƒìœ„ ê°’ì„ ì—…ë°ì´íŠ¸í•œë‹¤.

- Joint Classification and Detection.

    ![YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_13.png](YOLO9000%20Better,%20Faster,%20Stronger%20816596cb0d024569b2c301b25a4931b4/YOLO9000_13.png)

    1. Dataset.

        ì´ 9418ê°œì˜ Classë¥¼ ê°€ì§„ Datasetì´ ë§Œë“¤ì–´ì¡Œë‹¤.

        ê·¸ì¤‘ 9000ê°œì˜ ClassëŠ” ImageNetì— ì†í•˜ê³  Classification Labelë§Œ ë¶™ì–´ìžˆê¸° ë•Œë¬¸ì—, COCOë¥¼ ìœ„í•´ í•™ìŠµí•˜ëŠ” ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ì„ 4 : 1ë¡œ ë§žì·„ë‹¤.

    2. Training.

        í•´ë‹¹ ë¶€ë¶„ì—ì„œ Output Size ë¬¸ì œë¡œ 5ê°œì˜ Bounding Boxë¥¼ 3ê°œë¡œ ì¡°ì •í•˜ì˜€ë‹¤.

    3. Back Prop.

        Back Prop ì‹œ Imageê°€ ë‚˜ì˜¨ Datasetì— ë”°ë¼ Loss ê³„ì‚°ì´ ë‹¤ë¥´ë‹¤.

        - COCO Detection Dataset: Entire Loss Funtion.
        - ImageNet Classificaion Dataset: Classification Loss Function.
            - ì—¬ëŸ¬ Box ì¤‘ ê°€ìž¥ ë†’ì€ í™•ë¥ ì„ ë½‘ì•„ Classification Lossë¥¼ ê³„ì‚°í•œë‹¤.
            - Boxì™€ Ground Truthì˜ IOUê°€ 0.3 ì´ìƒì´ë©´ Entire Lossë¥¼ ê³„ì‚°í•œë‹¤.

    4. Validation.

        Validation Datasetì€ ImageNet Detection Datasetì„ ì‚¬ìš©í–ˆê³ , COCOì™€ 44ê°œì˜ Classë§Œ ê²¹ì³ìžˆì—ˆë‹¤.

        ì„±ëŠ¥ì€ 19.7mAPìœ¼ë¡œ, Labeling ë˜ì§€ ì•Šì€ 156ê°œì˜ Classë¥¼ í¬í•¨í•˜ë©´ 16.0mAPì´ë‹¤.

## Conclusion.

> We introduce YOLOv2 and YOLO9000, real-time de- tection systems. YOLOv2 is state-of-the-art and faster than other detection systems across a variety of detection datasets. Furthermore, it can be run at a variety of image sizes to provide a smooth tradeoff between speed and accu- racy.

> YOLO9000 is a real-time framework for detection more than 9000 object categories by jointly optimizing detection and classification. We use WordTree to combine data from various sources and our joint optimization technique to train simultaneously on ImageNet and COCO. YOLO9000 is a strong step towards closing the dataset size gap between de- tection and classification.

> Many of our techniques generalize outside of object de- tection. Our WordTree representation of ImageNet offers a richer, more detailed output space for image classification. Dataset combination using hierarchical classification would be useful in the classification and segmentation domains. Training techniques like multi-scale training could provide benefit across a variety of visual tasks.

> For future work we hope to use similar techniques for weakly supervised image segmentation. We also plan to improve our detection results using more powerful match- ing strategies for assigning weak labels to classification data during training. Computer vision is blessed with an enor- mous amount of labelled data. We will continue looking for ways to bring different sources and structures of data together to make stronger models of the visual world.

## Link.

[YOLO: Real-Time Object Detection](https://pjreddie.com/yolo9000/)