---

## Abstract.

- EfficientNetì€ PMLR í•™íšŒì—ì„œ 2019ë…„ì— ë°œí‘œëœ ë…¼ë¬¸ì´ë‹¤.
- CNNì—ì„œ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì‚¬ìš©í•œ ë°©ë²•: Fixed Resource Budget
    1. Depth: ëª¨ë¸ì˜ ê¹Šì´, Layer ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.
    2. Width: ë„ˆë¹„, Filter(or Channel) ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.
    3. Resolution: ì…ë ¥ ì´ë¯¸ì§€ì˜ í•´ìƒë„(í¬ê¸°), Input Imageì˜ í¬ê¸°ë¥¼ í‚¤ìš´ë‹¤.
    
- ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” CNNì˜ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ë°©ë²•: Compound Coefficient & EfficientNet
    1. Depth, Width, Resolutionì˜ ê· í˜•ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤.
    2. Compound Coefficientë¥¼ í†µí•´ Depth, Width, Resolutionë¥¼ Compound Scaling í•œë‹¤.
    3. NAS(Neural Architecture Search)ë¥¼ ì‚¬ìš©í•œ ìƒˆë¡œìš´ Baseline Network, EfficientNetì„ ì œì•ˆí•œë‹¤.
    4. EfficientNetì€ ë” ì •í™•í•˜ê³  íš¨ìœ¨ì (ì ì€ íŒŒë¼ë¯¸í„° ìˆ˜)ì´ë‹¤.
    5. EfficientNet-B7ì€ ImageNetì—ì„œ 84.3% Top-1 Accë¥¼ ë‹¬ì„±í–ˆë‹¤. ê¸°ì¡´ ConvNetì— ë¹„í•´ 8.4ë°° ì‘ê³ , 6.1ë°° ë¹ ë¥´ë‹¤. CIFAR-100(91.7%), Flowers(98.8%), 3 Other Transfer Learning Datasets â†’ SOTA
    
    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.55.56.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8455e113-4c99-42b7-ab0d-1ad34c9ee2c8/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.55.56.png)
    

## 1. Introduction.

1. CNNì—ì„œ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì‚¬ìš©í•œ ë°©ë²•
    
    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.56.37.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3fbcc6c7-684c-47e4-8e9c-cf45fb49efb1/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.56.37.png)
    
    1. (a)ë¥¼ Baselineìœ¼ë¡œ ì¡ì•˜ì„ ë•Œ, (b), (c), (d)ëŠ” ëª¨ë‘ í•˜ë‚˜ì˜ CNNì˜ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ë°©ë²•ì„ ì‚¬ìš©í•œ ê²ƒì´ë‹¤.
    2. (b): ë„ˆë¹„, Filter(or Channel) ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤. Wide Residual Network, Channelì„ 2ë°°ì”© ëŠ˜ë ¸ë‹¤.
    3. (c): ëª¨ë¸ì˜ ê¹Šì´, Layer ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤. ResNet-18ë¶€í„° ResNet-200ê¹Œì§€ Layerë¥¼ ëŠ˜ë ¸ë‹¤.
    4. (d): ì…ë ¥ ì´ë¯¸ì§€ì˜ í•´ìƒë„(í¬ê¸°), Input Imageì˜ í¬ê¸°ë¥¼ í‚¤ìš´ë‹¤. GPipe, Resolutionì„ 2ë°°ì”© ëŠ˜ë ¸ë‹¤.
    5. (e): ë²ˆì™¸ë¡œ, (b), (c), (d)ì˜ ë°©ë²•ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì˜€ë‹¤.
    
2. Compound Scaling Method
    1. Depth, Width, Resolutionì˜ ê· í˜•ì€ ê°ê°ì„ ì¼ì •í•œ ë¹„ìœ¨ë¡œ ì¦ê°€ì‹œí‚¤ë©´ ëœë‹¤.
    2. ê³ ì •ëœ ê³„ìˆ˜ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” Compound Scalingì„ ì œì•ˆí•œë‹¤.
    3. Depth($\alpha^N$), Width($\beta^N$), Image Size($\gamma^N$)
    4. $\alpha, \beta, \gamma$ëŠ” Constant Coeffcientsë¡œ, ê¸°ì¡´ Small Modelì—ì„œ Grid Searchë¥¼ í†µí•´ ê²°ì •ëœë‹¤.
    
3. EfficientNet
    1. ê¸°ì¡´ MobileNetê³¼ ResNetì— Compound Scaling Methodê°€ ì˜ ì‘ë™í•œë‹¤ëŠ” ê²ƒì„ ì‹¤í—˜ì„ í†µí•´ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.
    2. Compound Scaling Methodì˜ íš¨ê³¼ëŠ” Baseline Networkì— ë”°ë¼ í¬ê²Œ ë‹¬ë¼ì§„ë‹¤.
    

## 2. Related Work.

1. ConvNet Accuracy.
2. ConvNet Efficiency.
3. Model Scaling.

## 3. Compound Model Scaling.

- 3.1. Problem Formulation.
    1. ië²ˆ Conv LayerëŠ” $Y_i = F_i (X_i)$ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.
        - $F_i$: Layer Operator, Layer ì—°ì‚°ì„ ì˜ë¯¸.
        - $X_i, Y_i$: Input, Output, Tensor Shape $<H_i, W_i, C_i>$
        
    2. ìœ„ì˜ Conv Layer í‘œí˜„ì„ ì´ìš©í•˜ì—¬ CNNì„ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.
        
        $$N = \bigodot_{i=1...s} F^{L_i}_{i}(X_{<H_i, W_i, C_i>})$$
        
        - $F^{L_i}_{i}$: $F_i$ê°€ $L_i$ë§Œí¼ ë°˜ë³µ.
        - Conv Layerë¥¼ ê±°ì¹˜ë©´ Spatial Dimension(H, W)ëŠ” ì‘ì•„ì§€ê³  Channel Dimensionì´ ì¦ê°€í•œë‹¤.
        
    3. Optimization Problem.
        - ì¼ë°˜ì ì¸ CNN ë””ìì¸ì€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ $F_i$ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.
        - í•˜ì§€ë§Œ Model Scalingì€ $H_i, W_i, C_i, L_i$ë¥¼ í™•ì¥í•˜ê³  ì¡°ì ˆí•œë‹¤.
        - $F_i$ë¥¼ ê³ ì •í•˜ì—¬ ë¬¸ì œë¥¼ ë‹¨ìˆœí™”í•˜ì˜€ìœ¼ë‚˜, ê° Layerì—ì„œ ë‹¤ë¥¸ $H_i, W_i, C_i, L_i$ë¥¼ ì°¾ì•„ì•¼ í•˜ëŠ” ë„“ì€ Design Spaceê°€ ë‚¨ëŠ”ë‹¤.
        - Design Spaceë¥¼ ì¤„ì´ê¸° ìœ„í•´, ëª¨ë“  Layerì˜ ë¹„ìœ¨ì„ ì¼ì •í•˜ê²Œ ì¡°ì •í•˜ë„ë¡ ì œì•ˆí•œë‹¤.
        - Resource(GPU ì„±ëŠ¥)ê°€ ì œí•œëœ í™˜ê²½ì—ì„œ Model ì •í™•ë„ë¥¼ ìµœëŒ€í™” í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.
        - ì •í™•ë„ë¥¼ ë†’ì´ë©´ì„œ, ì—°ì‚°ëŸ‰ì€ ìµœëŒ€í•œ ì¤„ì¸ë‹¤.
        
        $$\underset{d,w,r}{\text{max}} \quad Accuracy(N(d, w, r)) \\ s.t. \quad N(d,w,r) = \bigodot_{i=1...s} \hat{F}^{d \cdot \hat{L}_i}_i (X_{<r \cdot \hat{H}_i, \ r \cdot \hat{W}_i, \ w \cdot \hat{C}_i>}) \\ \text{Memory}(N) \le \text{target\_memory} \\ \text{FLOPS}(N) \le \text{target\_flops}$$
        
        - $w, d, r$: Scalingì„ ìœ„í•œ ê³„ìˆ˜.
        - $H_i, W_i, C_i, L_i, F_i$: Baseline Networkì—ì„œ ë¯¸ë¦¬ ì •ì˜í•œ íŒŒë¼ë¯¸í„°ë“¤.
        
- 3.2. Scaling Dimensions.
    1. Difficulty of Optimization Problem
        1. $w, d, r$ì˜ ìµœì  ê°’ì´ ì„œë¡œ ì˜ì¡´ì ì´ê³ , ë¦¬ì†ŒìŠ¤ ì œì•½ ì¡°ê±´ ì•„ë˜ì—ì„œ ê°’ì´ ë³€í™”í•œë‹¤.
        2. ë”°ë¼ì„œ ê¸°ì¡´ ë°©ë²•ìœ¼ë¡œëŠ” ì´ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ì—¬ Scaling í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.
        
    
    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.56.48.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8d812f89-9fee-4e88-a1e4-0d69371f6728/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.56.48.png)
    
    1. Depth: ëª¨ë¸ì˜ ê¹Šì´, Layer ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.
        1. Intuition: Deep NetworkëŠ” Richer, Complexí•œ Featureë¥¼ í¬ì°©í•  ìˆ˜ ìˆë‹¤.
        2. í•˜ì§€ë§Œ ê¹Šì–´ì§ˆìˆ˜ë¡ Gradient Vanishingì´ ë°œìƒí•˜ì—¬ í•™ìŠµì— ì–´ë ¤ì›€ì´ ìƒê¸´ë‹¤.
        3. Gradient Vanishing í•´ê²°ì„ ìœ„í•´ Skip Connectionsê³¼ Batch Normë¥¼ ì‚¬ìš©í•œ ResNetì´ ë“±ì¥í–ˆì§€ë§Œ, 101ê³¼ 1000ì€ ì •í™•ë„ê°€ ë¹„ìŠ·í•˜ë©° ì—¬ì „íˆ ë¬¸ì œê°€ ì¡´ì¬í•œë‹¤.
        4. ê°€ìš´ë° ê·¸ë˜í”„ëŠ” Depthë§Œì„ ì¦ê°€ì‹œí‚¨ ì„±ëŠ¥ìœ¼ë¡œ, d=6.0ì—ì„œ ì¦ê°€í­ì´ ê±°ì˜ ì‚¬ë¼ì§„ë‹¤.
        
    2. Width: ë„ˆë¹„, Filter(or Channel) ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.
        1. Intuition: Wider NetworkëŠ” Fine-grained Featureë¥¼ í¬ì°©í•  ìˆ˜ ìˆê³ , Deep Networkì— ë¹„í•´ í•™ìŠµì´ ì‰½ë‹¤.
        2. í•˜ì§€ë§Œ Depthê°€ ì‘ì€ NetworkëŠ” Richer, Complexí•œ Featureë¥¼ í¬ì°©í•˜ê¸° ì–´ë µë‹¤.
        3. ì¢Œì¸¡ ê·¸ë˜í”„ëŠ” Widthë§Œì„ ì¦ê°€ì‹œí‚¨ ì„±ëŠ¥ìœ¼ë¡œ, w=3.8ì—ì„œ ì¦ê°€í­ì´ ê°ì†Œí•œë‹¤.
        
    3. Resolution: ì…ë ¥ ì´ë¯¸ì§€ì˜ í•´ìƒë„(í¬ê¸°), Input Imageì˜ í¬ê¸°ë¥¼ í‚¤ìš´ë‹¤.
        1. Intuition: Higher Resolutionì€ Fine-grained Patternsì„ í¬ì°©í•  ìˆ˜ ìˆë‹¤.
        2. ì´ˆê¸° í•´ìƒë„ëŠ” 224X224 ì˜€ìœ¼ë‚˜, ë…¼ë¬¸ ë‹¹ì‹œ 600X600ì—ì„œ í•™ìŠµì´ ê°€ëŠ¥í–ˆë‹¤.
        3. ìš°ì¸¡ ê·¸ë˜í”„ëŠ” Resolutionë§Œì„ ì¦ê°€ì‹œí‚¨ ì„±ëŠ¥ìœ¼ë¡œ, ê°€ì¥ ì¦ê°€í­ì˜ ê°ì†Œê°€ ë”ë””ë‹¤.
    
    1. Observation 1.
        
        > Scaling up any dimension of network width, depth, or resolution improves accuracy, but the accuracy gain diminishes for bigger models.
        > 
    
- 3.3. Compound Scaling.
    1. Figure 4.
        
        ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.57.12.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/33146d69-748c-45e0-8230-16706a1757d4/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.57.12.png)
        
        1. 3.2.ë¥¼ í†µí•´ Different Scaling Dimensionì€ ë…ë¦½ì ì´ì§€ ì•Šë‹¤ëŠ” ê±¸ ì•Œ ìˆ˜ ìˆë‹¤.
        2. ë”°ë¼ì„œ ëª¨ë“  ì°¨ì›ì„ Scaling í•˜ì—¬ ê· í˜•ì„ ë§ì¶°ì•¼ í•œë‹¤.
        3. ìœ„ ê·¸ë˜í”„ëŠ” Depthì™€ Resolution, ë‘ ì°¨ì›ì„ Scalingí•œ ê²°ê³¼ì´ë‹¤.
        4. Widthë¥¼ ê³ ì •í•˜ê³  Depthì™€ Resolution ê°ê° ë‹¤ë¥¸ ë¹„ìœ¨ë¡œ ì¦ê°€ì‹œí‚¨ ê²½ìš°, ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
        
    2. Observation 2.
        
        > In order to pursue better accuracy and efficiency, it is critical to balance all dimensions of network width, depth, and resolution during ConvNet scaling.
        > 
        
    3. Compound Scaling Method.
        
        $$\text{depth}: d = \alpha^{\phi} \\ \text{width}: w = \beta^{\phi} \\ \text{resolution}: r = \gamma^{\phi} \\ s.t. \ \alpha \cdot \beta^2 \cdot \gamma^2 \approx 2 \\ \alpha \ge 1, \beta \ge 1, \gamma \ge 1$$
        
        1. Compound Coeffcient $\phi$ë¥¼ ì‚¬ìš©í•˜ì—¬ w, d, rì„ Scaling í•œë‹¤.
        2. $\alpha, \beta, \gamma$ëŠ” Small Grid Searchë¡œ ê²°ì •ë˜ëŠ” ìƒìˆ˜ì´ë‹¤.
        3. Compound Coeffcient $\phi$ëŠ” ë¦¬ì†ŒìŠ¤ì— ë”°ë¼ ì‚¬ìš©ìê°€ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤.
        4. Depthë¥¼ 2ë°° í•˜ë©´ FLOPSëŠ” 2ë°° ì¦ê°€í•˜ì§€ë§Œ, Widthë‚˜ Resolutionì„ 2ë°°í•˜ë©´ FLOPSëŠ” 4ë°° ì¦ê°€í•˜ê¸° ë•Œë¬¸ì—, $\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2$ë¡œ ì„¤ì •í•˜ì˜€ë‹¤.
        5. ì´ëŸ¬í•œ Total FLOPS ì„¤ì •ì€ ì–´ë–¤ $\phi$ë¥¼ ì‚¬ìš©í•´ë„ $2^\phi$ ë§Œí¼ ì¦ê°€í•˜ë„ë¡ í•œë‹¤.
        

## 4. EfficientNet Architecture.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.57.49.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4352bc3d-ee84-44d3-8b59-0fb0a8bb8720/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.57.49.png)

- Model Scalingìœ¼ë¡œ ìœ„ì—ì„œ $F_i$ë¥¼ ê³ ì •í•˜ì˜€ê¸° ë•Œë¬¸ì—, ì¢‹ì€ Baseline Networkê°€ ì¤‘ìš”í•˜ë‹¤.
- Compound Scalingì„ ê¸°ì¡´ CNNì—ë„ ì ìš©í•˜ì§€ë§Œ, ìƒˆë¡œìš´ Mobile-size Baselineì„ ì„¤ê³„í•˜ì˜€ë‹¤.
- EfficientNet-B0ì€ ê°€ì¥ Baseí•œ Networkë¡œ ìœ„ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤.
- ResNetì˜ Bottlenectì€ Channelì„ ë§ˆì§€ë§‰ì—ì„œ 4ë°° ì¦ê°€ì‹œí‚¤ì§€ë§Œ, Inverted Bottleneckì€ ì¤‘ê°„ì— ì¦ê°€ì‹œí‚¤ê³  ë§ˆì§€ë§‰ì— ê°ì†Œì‹œí‚¨ë‹¤.

*MBConv: Mobile Inverted Bottleneck.

---

<aside>
ğŸ‘£ STEP 1: we first fix $\phi$ = 1, assuming twice more resources available, and do a small grid search of $\alpha$, $\beta$, $\gamma$ based on Equation 2 and 3. In particular, we find the best values for EfficientNet-B0 are $\alpha$ = 1.2, $\beta$ = 1.1, $\gamma$ = 1.15, under constraint of $\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2$.

</aside>

<aside>
ğŸ‘£ STEP 2: we then fix $\alpha$, $\beta$, $\gamma$ as constants and scale up
baseline network with different $\phi$ using Equation 3, to
obtain EfficientNet-B1 to B7 (Details in Table 2)

</aside>

1. Compound Coefficient $\phi$ë¥¼ 1ë¡œ ê³ ì •í•˜ê³  $\alpha$, $\beta$, $\gamma$ë¥¼ êµ¬í•œë‹¤.
2. $\alpha$, $\beta$, $\gamma$ë¥¼ ê³ ì •í•˜ê³  ì„œë¡œ ë‹¤ë¥¸ $\phi$ë¡œ Scaling í•˜ì—¬, EfficientNet-B1 to B7ì„ ìƒì„±í•œë‹¤.

---

- ë²ˆì™¸ ì´ë¯¸ì§€.
    
    ![á„ƒá…¡á„‹á…®á†«á„…á…©á„ƒá…³.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e8ccf575-3563-4607-9270-28e11359f0ba/á„ƒá…¡á„‹á…®á†«á„…á…©á„ƒá…³.png)
    
    ![á„ƒá…¡á„‹á…®á†«á„…á…©á„ƒá…³ (1).png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/60cf515a-0bf3-48f9-bdfc-20e46e4bbfff/á„ƒá…¡á„‹á…®á†«á„…á…©á„ƒá…³_(1).png)
    

## 5. Experiments.

### 5.1. Scaling Up MobileNets and ResNets.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.58.30.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f11b45cf-d46c-443f-b1f2-a94afe28596f/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.58.30.png)

- MoblieNetsê³¼ ResNetsì— Compound Scalingì„ ì ìš©í•˜ì˜€ë‹¤.
- ê¸°ì¡´ FLOPSì™€ í¬ê²Œ ë‹¬ë¼ì§€ì§€ ì•Šì•˜ì§€ë§Œ, ì •í™•ë„ê°€ ë†’ì•„ì¡Œë‹¤.
- Baseline Networkì˜ ì¤‘ìš”ì„±ì„ ë³¼ ìˆ˜ ìˆë‹¤.

### 5.2. ImageNet Results for EfficientNet.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.58.10.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ce583922-a572-463d-a7f0-13d780989880/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.58.10.png)

- íŒŒë¼ë¯¸í„° ìˆ˜(FLOPS) ë³„ë¡œ ëª¨ë¸ì„ ì •ë ¬í•˜ì˜€ë‹¤.
- EfficientNet-B7ì€ ê¸°ì¡´ SOTAì¸ GPipeì™€ ë™ì¼í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì§€ë§Œ, íŒŒë¼ë¯¸í„°ìˆ˜ëŠ” ì•½ 8.4ë°° ì ë‹¤.

---

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.59.02.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2edaec06-6b57-44d7-adc6-74947acbc035/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.59.02.png)

- Abstractì˜ Figure 1.ê³¼ ìœ ì‚¬í•œ ê·¸ë˜í”„ì´ë‹¤.
- Figure 1.ì€ Number of Parametersë¡œ, Figure 5.ëŠ” FLOPSë¡œ ë¹„êµí•˜ì˜€ë‹¤.
- EfficientNetì´ ë†’ì€ ì •í™•ë„ì™€ ì ì€ ì—°ì‚°ëŸ‰ì„ ë³´ì—¬ì¤€ë‹¤.

---

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.58.44.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/979092ec-efd4-4b42-9999-20b90896e668/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.58.44.png)

- Batch Size 1, Single Core ...ìœ¼ë¡œ ë¹„êµí•œ ì§€ì—° ì‹œê°„ ê²°ê³¼ì´ë‹¤.
- EfficientNet-B7ì´ ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ë³´ì—¬ì¤€ë‹¤.

### 5.3. Transfer Learning Results for EfficientNet.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.59.19.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f0514c34-bc89-48cf-8a8a-70dfacc311ec/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.59.19.png)

- Transfer Learningì˜ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ì´ë‹¤.
- ì ì€ íŒŒë¼ë¯¸í„° ìˆ˜ë¡œ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ë‚˜ì€ ì •í™•ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.

---

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 22.59.43.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3c533f38-8497-4108-8ede-4c5f02d98d4b/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_22.59.43.png)

- Transfer Learningì˜ ì„±ëŠ¥ì„ ê·¸ë˜í”„ë¡œ ë¹„êµí•œ ê²ƒì´ë‹¤.
- ë¹¨ê°„ ì„ ì´ EfficientNetì˜ ì •í™•ë„ì´ê³ , ë‹¤ë¥¸ Modelì€ ê°ì ë‹¤ë¥¸ ê¸°í˜¸ë¥¼ ê°€ì§€ê³  ìˆë‹¤.

---

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 23.00.18.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7a16bbc5-7463-4318-8031-5e65cd4f19d3/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_23.00.18.png)

- Transfer Learningì— ì‚¬ìš©í•œ Datasetì´ë‹¤.

## 6. Discussion.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 23.00.40.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/79699a6d-c427-4c59-bd2b-41ecd68f75c1/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_23.00.40.png)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 23.00.53.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f8079248-bbf3-43ed-810c-640abb89033e/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_23.00.53.png)

- Baselineì¸ EfficientNet-B0ì— ëŒ€í•´ ê°ê° ë‹¤ë¥¸ Scalingì„ ì ìš©í•œ ê²°ê³¼ì´ë‹¤.

---

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 23.00.01.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d75b265c-e137-4b4f-b7d4-e14be1a250e7/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_23.00.01.png)

- CAMì€ ì´ë¯¸ì§€ì—ì„œ ì–´ë–¤ ë¶€ë¶„ì´ í™œì„±í™” ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- ë¹¨ê°„ìƒ‰ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í•´ë‹¹í•˜ëŠ” Classê°€ ê°•í•˜ê²Œ ë°˜ì‘í•˜ê³ , íŒŒë€ìƒ‰ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì•½í•˜ê²Œ ë°˜ì‘í•œë‹¤.

## 7. Conclusion.

- Compound Scaling.
- EfficientNet.

## Acknowledgements.

> We thank Ruoming Pang, Vijay Vasudevan, Alok Aggarwal, Barret Zoph, Hongkun Yu, Jonathon Shlens, Raphael Gon- tijo Lopes, Yifeng Lu, Daiyi Peng, Xiaodan Song, Samy Bengio, Jeff Dean, and the Google Brain team for their help.
> 

## Appendix.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-09 23.51.34.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6b926f29-d1a5-4578-9503-ff8b5d7793d4/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-09_23.51.34.png)

## Link.

[EfficientNet : Rethinking Model Scaling for Convolutional Neural Networks ë…¼ë¬¸ ë¦¬ë·°](https://ropiens.tistory.com/110)