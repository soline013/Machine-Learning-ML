{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3136,
     "status": "ok",
     "timestamp": 1620898688574,
     "user": {
      "displayName": "Sollie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggc0JaN30ymRKWs8Cn_SH_4sZX_Wk07mpSyO_Np=s64",
      "userId": "15228865098189385229"
     },
     "user_tz": -540
    },
    "id": "qGrNWMo0bq__",
    "outputId": "fc8eedc6-9eb0-41cf-c5c8-4828dbff5b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (0.8.6.2)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (0.13.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (3.17.3)\n",
      "Requirement already satisfied: wheel in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (3.4.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from mediapipe) (1.21.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from matplotlib->mediapipe) (8.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/ML/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIT2CIkrpz0g"
   },
   "source": [
    "# Hands - mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwIS_xq3p3IE"
   },
   "source": [
    "[Hands - mediapipe](https://google.github.io/mediapipe/solutions/hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EPHGFgZCdTdP"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "#Not Google Colab.\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "90HVZv3Cdfzn"
   },
   "outputs": [],
   "source": [
    "#We need the list format.\n",
    "file_list = [\"hand1.jpeg\", \"hand2.jpeg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6569,
     "status": "ok",
     "timestamp": 1620898692031,
     "user": {
      "displayName": "Sollie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggc0JaN30ymRKWs8Cn_SH_4sZX_Wk07mpSyO_Np=s64",
      "userId": "15228865098189385229"
     },
     "user_tz": -540
    },
    "id": "KAQ0Es4TdRlz",
    "outputId": "3100a777-6691-45b9-fbbf-4089744a35f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handedness: [classification {\n",
      "  index: 1\n",
      "  score: 0.98769211769104\n",
      "  label: \"Right\"\n",
      "}\n",
      "]\n",
      "hand_landmarks: landmark {\n",
      "  x: 0.425089031457901\n",
      "  y: 0.8741721510887146\n",
      "  z: -0.00013987628335598856\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5231956243515015\n",
      "  y: 0.9459242224693298\n",
      "  z: 0.054630130529403687\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6019830107688904\n",
      "  y: 0.9416624307632446\n",
      "  z: 0.07406506687402725\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6682078838348389\n",
      "  y: 0.8953105211257935\n",
      "  z: 0.09222705662250519\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7169435024261475\n",
      "  y: 0.8697617053985596\n",
      "  z: 0.12073211371898651\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6596882343292236\n",
      "  y: 0.7729544639587402\n",
      "  z: -0.007162433583289385\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7862423062324524\n",
      "  y: 0.6644973754882812\n",
      "  z: -0.01662610098719597\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8576486706733704\n",
      "  y: 0.6021419763565063\n",
      "  z: -0.021400323137640953\n",
      "}\n",
      "landmark {\n",
      "  x: 0.9059901833534241\n",
      "  y: 0.5523805022239685\n",
      "  z: -0.029292471706867218\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6252163052558899\n",
      "  y: 0.6905555129051208\n",
      "  z: -0.020159179344773293\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7573775053024292\n",
      "  y: 0.5610834956169128\n",
      "  z: -0.03789064660668373\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8320642709732056\n",
      "  y: 0.4830861985683441\n",
      "  z: -0.053578827530145645\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8865859508514404\n",
      "  y: 0.42202138900756836\n",
      "  z: -0.07642582803964615\n",
      "}\n",
      "landmark {\n",
      "  x: 0.57896888256073\n",
      "  y: 0.629137396812439\n",
      "  z: -0.025410648435354233\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6882923245429993\n",
      "  y: 0.5016957521438599\n",
      "  z: -0.03647497668862343\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7598215937614441\n",
      "  y: 0.42080751061439514\n",
      "  z: -0.04987807944417\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8144034147262573\n",
      "  y: 0.36297762393951416\n",
      "  z: -0.05969354510307312\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5238713622093201\n",
      "  y: 0.5940645933151245\n",
      "  z: -0.01608920842409134\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5911287069320679\n",
      "  y: 0.47500666975975037\n",
      "  z: -0.026977183297276497\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6272469758987427\n",
      "  y: 0.40980786085128784\n",
      "  z: -0.035180043429136276\n",
      "}\n",
      "landmark {\n",
      "  x: 0.659864604473114\n",
      "  y: 0.35658904910087585\n",
      "  z: -0.049112848937511444\n",
      "}\n",
      "\n",
      "Index finger tip coordinates:  (695.8004608154297, 282.8188171386719)\n",
      "Handedness: [classification {\n",
      "  index: 0\n",
      "  score: 0.9304468035697937\n",
      "  label: \"Left\"\n",
      "}\n",
      "]\n",
      "hand_landmarks: landmark {\n",
      "  x: 0.16884128749370575\n",
      "  y: 0.7707194089889526\n",
      "  z: -0.000263929832726717\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3583182692527771\n",
      "  y: 0.8039079308509827\n",
      "  z: -0.041553303599357605\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4929812252521515\n",
      "  y: 0.7569184899330139\n",
      "  z: -0.0867878794670105\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5874218344688416\n",
      "  y: 0.6713516116142273\n",
      "  z: -0.11206191778182983\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6618136167526245\n",
      "  y: 0.5954218506813049\n",
      "  z: -0.12103857100009918\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4604474902153015\n",
      "  y: 0.6032191514968872\n",
      "  z: -0.20868365466594696\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6113018989562988\n",
      "  y: 0.4644874930381775\n",
      "  z: -0.23720857501029968\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6927471160888672\n",
      "  y: 0.38556790351867676\n",
      "  z: -0.23789596557617188\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7546821236610413\n",
      "  y: 0.3265013098716736\n",
      "  z: -0.23859629034996033\n",
      "}\n",
      "landmark {\n",
      "  x: 0.36753174662590027\n",
      "  y: 0.5514835119247437\n",
      "  z: -0.17589271068572998\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5264504551887512\n",
      "  y: 0.39725109934806824\n",
      "  z: -0.23139818012714386\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6137375831604004\n",
      "  y: 0.3037734627723694\n",
      "  z: -0.2372893989086151\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6794345378875732\n",
      "  y: 0.22843360900878906\n",
      "  z: -0.2479103058576584\n",
      "}\n",
      "landmark {\n",
      "  x: 0.27833086252212524\n",
      "  y: 0.5227311849594116\n",
      "  z: -0.1271834820508957\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4098667502403259\n",
      "  y: 0.37873172760009766\n",
      "  z: -0.15949490666389465\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4876478612422943\n",
      "  y: 0.28500431776046753\n",
      "  z: -0.16197340190410614\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5441669821739197\n",
      "  y: 0.21318042278289795\n",
      "  z: -0.164237380027771\n",
      "}\n",
      "landmark {\n",
      "  x: 0.19829131662845612\n",
      "  y: 0.5183488726615906\n",
      "  z: -0.07028001546859741\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2963577210903168\n",
      "  y: 0.3968846797943115\n",
      "  z: -0.09086092561483383\n",
      "}\n",
      "landmark {\n",
      "  x: 0.34723031520843506\n",
      "  y: 0.3313509225845337\n",
      "  z: -0.09240994602441788\n",
      "}\n",
      "landmark {\n",
      "  x: 0.38640254735946655\n",
      "  y: 0.27698540687561035\n",
      "  z: -0.10370322316884995\n",
      "}\n",
      "\n",
      "Index finger tip coordinates:  (467.9029166698456, 270.01658326387405)\n"
     ]
    }
   ],
   "source": [
    "# For static images:\n",
    "with mp_hands.Hands(static_image_mode=True,\n",
    "                    max_num_hands=2,\n",
    "                    min_detection_confidence=0.5) as hands:\n",
    "  for idx, file in enumerate(file_list):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see above).\n",
    "    image = cv2.flip(cv2.imread(file), 1) #Previous Parameter: 0\n",
    "\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "    print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      print('hand_landmarks:', hand_landmarks)\n",
    "      print(\n",
    "        f'Index finger tip coordinates: ',\n",
    "        f'({hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width},',\n",
    "        f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "      )\n",
    "      mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "    \n",
    "    #Print Annotated Image.\n",
    "    cv2.imshow('Annotated Image', cv2.flip(annotated_image, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1AFuUyhbu7uf3FmstwJjd64bPSmq4cvrN"
    },
    "executionInfo": {
     "elapsed": 71008,
     "status": "ok",
     "timestamp": 1620898756479,
     "user": {
      "displayName": "Sollie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggc0JaN30ymRKWs8Cn_SH_4sZX_Wk07mpSyO_Np=s64",
      "userId": "15228865098189385229"
     },
     "user_tz": -540
    },
    "id": "AXUBH4fidOI1",
    "outputId": "1c588605-8833-42c8-aaf0-99fb3bf66c62"
   },
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "#Previous Code: cap = cv2.VideoCapture(\"/content/HandVideo.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    \n",
    "    # If loading a video, use 'break' instead of 'continue'.\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      break #Previous Code: continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display,\n",
    "    # and convert the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance,\n",
    "    # optionally mark the image as not writeable to pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "          image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    #Previous Code: cv2.imshow('MediaPipe Hands', image)\n",
    "    cv2.imshow('image' ,image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`STATIC_IMAGE_MODE`: false는 Video Stream이고, true는 Static Image이다. Default는 false이다.\n",
    "\n",
    "`MAX_NUM_HANDS`: 최대로 Detect 할 수 있는 손의 개수이다. Default는 2이다.\n",
    "\n",
    "`MIN_DETECTION_CONFIDENCE`: [0.0, 1.0] 값으로, 탐지가 되는 최소 신뢰값이다. Default는 0.5이다.\n",
    "\n",
    "`MIN_TRACKING_CONFIDENCE`: [0.0, 1.0] 값으로, 랜드마크 추적 모델의 최소 신뢰값이다. 이 값을 높이면 대기 시간이 길어져도 Solution의 견고성을 높일 수 있다. true는 무시되고, Default는 0.5이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG-ekyV1dLjl"
   },
   "source": [
    "## Naver Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWjonvbQpOn5"
   },
   "source": [
    "[Naver Blog](https://blog.naver.com/skyjjw79/222327014865)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RGHS83jeaQVI"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 71012,
     "status": "error",
     "timestamp": 1620898756490,
     "user": {
      "displayName": "Sollie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggc0JaN30ymRKWs8Cn_SH_4sZX_Wk07mpSyO_Np=s64",
      "userId": "15228865098189385229"
     },
     "user_tz": -540
    },
    "id": "VGiIzLj_aX_K",
    "outputId": "86bef57e-3c2d-484a-b925-e4bcdfa67ab7"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3751418e60f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mhandLms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandLms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "my_hands = mp_hands.Hands()\n",
    "\n",
    "while True:\n",
    "  success, img = cap.read()\n",
    "  imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  result = my_hands.process(imgRGB)\n",
    "\n",
    "  if result.multi_hand_landmarks:\n",
    "    for handLms in results.multi_hand_landmarks:\n",
    "      for id, lm in enumerate(handLms.landmark):\n",
    "        h, w, c = img.shape\n",
    "        cx, xy = int(lm.x * w), int(lm.y * h)\n",
    "        print(id, \":\", cx, cy)\n",
    "        if id == 0:\n",
    "          cv2.circle(img, (cx, cy), 20, (255, 0, 0), cv2.FILLED)\n",
    "      mp_drawing.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "  cv2.imshow(\"Gotcha\", img)\n",
    "  cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJGcOhMKrxpe"
   },
   "source": [
    "## OpenCV VidoCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "executionInfo": {
     "elapsed": 640,
     "status": "error",
     "timestamp": 1620898767737,
     "user": {
      "displayName": "Sollie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggc0JaN30ymRKWs8Cn_SH_4sZX_Wk07mpSyO_Np=s64",
      "userId": "15228865098189385229"
     },
     "user_tz": -540
    },
    "id": "BwdWLG1WrytB",
    "outputId": "22980f6b-afe7-4b6e-a6d6-7f34697ac790",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.0 720.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bbc3acd79808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(3), cap.get(4))\n",
    "ret = cap.set(3,320)\n",
    "ret = cap.set(4,240)\n",
    "while(True):\n",
    "    ret, frame = cap.read() \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame', gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-R87Imyr4zS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNWzP88adTsmL8Zy65zHhIL",
   "collapsed_sections": [],
   "name": "mediapipe_hands.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
