{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "cnn-with-tensorflow-keras-for-fashion-mnist_CP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PUu66wsXD3bE",
        "4uOtkGD8D3b0",
        "KZk0V_KgD3cX",
        "vNmNmWUmD3cm",
        "2Teg36UeD3dq",
        "3zvx4eTBD3ee",
        "h-I0jCLqD3eu",
        "bxEiWvWcD3fR",
        "qtHBMAhKD3gS",
        "nGpLnZb1D3gk",
        "pilKm6BpD3hd",
        "dQ1e5a1gD3hl",
        "4s-FFmcdD3nF",
        "kE5ZAdoFD3p5",
        "JtaFGwPDD3vS"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soline013/Machine_Learning-ML/blob/master/cnn_with_tensorflow_keras_for_fashion_mnist_CP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "805a97911f01abb36ff8414d8d6aec9293e4fb85",
        "id": "M6QKJud6D3Xs"
      },
      "source": [
        " <h1><center><font size=\"6\">CNN with Tensorflow|Keras for Fashion MNIST</font></center></h1>\n",
        "\n",
        "\n",
        "<img src=\"https://kaggle2.blob.core.windows.net/datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-card.png\" width=\"400\"></img>\n",
        "\n",
        "\n",
        "# <a id='0'>Content</a>\n",
        "\n",
        "- <a href='#1'>Introduction</a>  \n",
        "- <a href='#2'>Load packages</a>  \n",
        "- <a href='#3'>Read the data</a>  \n",
        "- <a href='#4'>Data exploration</a>\n",
        "    - <a href='#41'>Class distribution</a>\n",
        "    - <a href='#42'>Images samples</a>\n",
        "- <a href='#5'>Model</a>  \n",
        "    - <a href='#51'>Prepare the model</a>  \n",
        "    - <a href='#52'>Train the model</a>  \n",
        "    - <a href='#53'>Test prediction accuracy</a>   \n",
        "    - <a href='#54'>Validation accuracy and loss</a>   \n",
        "    - <a href='#55'>Add Dropout layers to the model</a>  \n",
        "    - <a href='#56'>Re-train the model</a>   \n",
        "    - <a href='#57'>Check validation accuracy and loss with the new model</a>    \n",
        "    - <a href='#58'>Prediction accuracy with the new model </a>   \n",
        "- <a href='#6'>Visualize the classified images</a>  \n",
        "    - <a href='#61'>Correctly classified images</a>   \n",
        "    - <a href='#62'>Incorrectly classified images</a>   \n",
        "- <a href='#7'>Conclusions</a>\n",
        "- <a href='#8'>References</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1b1c16628c2f62a18e1dc2068e1d67d7003922b1",
        "id": "sSJfQ0kJD3X6"
      },
      "source": [
        "# <a id=\"1\">Introduction</a>  \n",
        "\n",
        "\n",
        "## Dataset\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "\n",
        "## Content\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.   \n",
        "\n",
        "Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.   \n",
        "\n",
        "The training and test data sets have 785 columns.   \n",
        "\n",
        "The first column consists of the class labels (see above), and represents the article of clothing. \n",
        "\n",
        "The rest of 784 columns (1-785) contain the pixel-values of the associated image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5a708dc52b2e5990e2247ed573d50d0f6933b730",
        "id": "hEZLWjdLD3YD"
      },
      "source": [
        "# <a id=\"2\">Load packages</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2defa674e4e6d0e7371df92e7d1f388fc5c14bb6",
        "trusted": true,
        "id": "yLIk07wRD3YN",
        "outputId": "d21d50ef-0d96-4d66-c63e-f34306bdc3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly import tools\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e17fd2539412442ddb3ecacf84366ddd62faf836",
        "id": "4irynXsaD3Yi"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d7a44bfc7a28df7026241c4a7e047298446f1554",
        "trusted": true,
        "id": "wml63MtlD3Yk",
        "outputId": "1391c940-d9ff-416d-a36f-86bdd2a1ac9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "IMG_ROWS = 28\n",
        "IMG_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 2018\n",
        "#Model\n",
        "NO_EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "IS_LOCAL = False\n",
        "\n",
        "import os\n",
        "\n",
        "if(IS_LOCAL):\n",
        "    PATH=\"../input/fashionmnist/\"\n",
        "else:\n",
        "    PATH=\"../input/\"\n",
        "print(os.listdir(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-acb55306edba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../input/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f49d65b4af77e87ab34b6854850619911cff1e6d",
        "id": "qprdSaDXD3ZP"
      },
      "source": [
        "# <a id=\"3\">Read the data</a>\n",
        "\n",
        "There are 10 different classes of images, as following: \n",
        "\n",
        "* **0**: **T-shirt/top**;   \n",
        "* **1**: **Trouser**;   \n",
        "* **2**: **Pullover**;   \n",
        "* **3**: **Dress**;\n",
        "* **4**: **Coat**;\n",
        "* **5**: **Sandal**;\n",
        "* **6**: **Shirt**;\n",
        "* **7**: **Sneaker**;\n",
        "* **8**: **Bag**;\n",
        "* **9**: **Ankle boot**.\n",
        "\n",
        "Image dimmensions are **28**x**28**.   \n",
        "\n",
        "The train set and test set are given in two separate datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a9c3148fda056ecc88570b302f5185064d5e9fc8",
        "trusted": true,
        "id": "5eDFTMraD3ZR"
      },
      "source": [
        "train_file = PATH+\"fashion-mnist_train.csv\"\n",
        "test_file  = PATH+\"fashion-mnist_test.csv\"\n",
        "\n",
        "train_data = pd.read_csv(train_file)\n",
        "test_data = pd.read_csv(test_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "290f8f38b2f64dfd1bd3432eb1e9a101dbbaf4e5",
        "id": "aDhg7SDzD3Zh"
      },
      "source": [
        "# <a id=\"4\">Data exploration</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e8891ae7996aa2ae5bc1c025661a77ae91c2fdfb",
        "id": "EzN02Y7ND3Zj"
      },
      "source": [
        "![](http://)The dimmension of the original  train,  test set are as following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a133496cefc53baa56b9a5eec93bfd064ea6360d",
        "id": "vwXHkRzkD3Zl"
      },
      "source": [
        "print(\"Fashion MNIST train -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])\n",
        "print(\"Fashion MNIST test -  rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dc317fbf40c9b2838f8091e745a64e060a7affc0",
        "id": "NSeZUUEOD3Zw"
      },
      "source": [
        "## <a id=\"41\">Class distribution</a>\n",
        "\n",
        "Let's see how many number of images are in each class. We start with the train set.\n",
        "\n",
        "### Train set images class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "da948eb587daf81160a4794a36662f8872c882a4",
        "id": "Si__IXKwD3Zy"
      },
      "source": [
        "# Create a dictionary for each type of label \n",
        "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
        "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
        "\n",
        "def get_classes_distribution(data):\n",
        "    # Get the count for each label\n",
        "    label_counts = data[\"label\"].value_counts()\n",
        "\n",
        "    # Get total number of samples\n",
        "    total_samples = len(data)\n",
        "\n",
        "\n",
        "    # Count the number of items in each class\n",
        "    for i in range(len(label_counts)):\n",
        "        label = labels[label_counts.index[i]]\n",
        "        count = label_counts.values[i]\n",
        "        percent = (count / total_samples) * 100\n",
        "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
        "\n",
        "get_classes_distribution(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fc41d889d3ad6352994cdf8a76a78ed0d22ec141",
        "id": "N-FWCnFqD3ai"
      },
      "source": [
        "The classes are equaly distributed in the train set (10% each). Let's check the same for the test set.    \n",
        "Let's also plot the class distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7ac8f6fde6bd78553f08469093cebc0e124a5210",
        "id": "O42JzO8YD3aj"
      },
      "source": [
        "def plot_label_per_class(data):\n",
        "    f, ax = plt.subplots(1,1, figsize=(12,4))\n",
        "    g = sns.countplot(data.label, order = data[\"label\"].value_counts().index)\n",
        "    g.set_title(\"Number of labels for each class\")\n",
        "\n",
        "    for p, label in zip(g.patches, data[\"label\"].value_counts().index):\n",
        "        g.annotate(labels[label], (p.get_x(), p.get_height()+0.1))\n",
        "    plt.show()  \n",
        "    \n",
        "plot_label_per_class(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f7c3328ce859d1809ce916bba73bc57b2d580963",
        "id": "PUu66wsXD3bE"
      },
      "source": [
        "### Test set images class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "2581093ff1268ae9487fe83b383c2d4be4657000",
        "id": "ZyEzHtCSD3bK"
      },
      "source": [
        "get_classes_distribution(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fffa6f5248eb037b47a84e1e1ee889ee3470a1d4",
        "id": "3Nf1F_n8D3bk"
      },
      "source": [
        "Also in the test set the 10 classes are equaly distributed (10% each).  \n",
        "\n",
        "Lets' also plot the class distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7d770b2cde8f32b83a67da02eeacd17f01904ddd",
        "id": "OJ-JCq48D3bm"
      },
      "source": [
        "plot_label_per_class(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "588beb3c38b5f5a0b41ca0699426a1477efb8412",
        "id": "4uOtkGD8D3b0"
      },
      "source": [
        "## <a id=\"42\">Sample images</a>\n",
        "\n",
        "### Train set images\n",
        "\n",
        "Let's plot some samples for the images.   \n",
        "We add labels to the train set images, with the corresponding fashion item category.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "62fd41c12740f184ec160d692b3289d4457297d6",
        "id": "aF9q2wuQD3b1"
      },
      "source": [
        "def sample_images_data(data):\n",
        "    # An empty list to collect some samples\n",
        "    sample_images = []\n",
        "    sample_labels = []\n",
        "\n",
        "    # Iterate over the keys of the labels dictionary defined in the above cell\n",
        "    for k in labels.keys():\n",
        "        # Get four samples for each category\n",
        "        samples = data[data[\"label\"] == k].head(4)\n",
        "        # Append the samples to the samples list\n",
        "        for j, s in enumerate(samples.values):\n",
        "            # First column contain labels, hence index should start from 1\n",
        "            img = np.array(samples.iloc[j, 1:]).reshape(IMG_ROWS,IMG_COLS)\n",
        "            sample_images.append(img)\n",
        "            sample_labels.append(samples.iloc[j, 0])\n",
        "\n",
        "    print(\"Total number of sample images to plot: \", len(sample_images))\n",
        "    return sample_images, sample_labels\n",
        "\n",
        "train_sample_images, train_sample_labels = sample_images_data(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e5c80cef30985bb5ab0ee48d4fc9891660c2a92f",
        "id": "_gAHBZxpD3cO"
      },
      "source": [
        "Let's now plot the images.   \n",
        "The labels are shown above each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4f4f27f5143bdd834302a2c43cdb1d68d2a131a9",
        "id": "KOrCvwEQD3cQ"
      },
      "source": [
        "def plot_sample_images(data_sample_images,data_sample_labels,cmap=\"Blues\"):\n",
        "    # Plot the sample images now\n",
        "    f, ax = plt.subplots(5,8, figsize=(16,10))\n",
        "\n",
        "    for i, img in enumerate(data_sample_images):\n",
        "        ax[i//8, i%8].imshow(img, cmap=cmap)\n",
        "        ax[i//8, i%8].axis('off')\n",
        "        ax[i//8, i%8].set_title(labels[data_sample_labels[i]])\n",
        "    plt.show()    \n",
        "    \n",
        "plot_sample_images(train_sample_images,train_sample_labels, \"Greens\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "bd30352b2674a20eca5e792d7c186cdcbab25461",
        "id": "KZk0V_KgD3cX"
      },
      "source": [
        "### Test set images\n",
        "\n",
        "Let's plot now a selection of the test set images.  \n",
        "Labels are as well added (they are known).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "616df96bfae0e8065c206e6dfec2847d5d42125d",
        "id": "qa4H4iRdD3cZ"
      },
      "source": [
        "test_sample_images, test_sample_labels = sample_images_data(test_data)\n",
        "plot_sample_images(test_sample_images,test_sample_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "273c79c7470c49fe7a546dd7148e0536be2dee19",
        "id": "0fuNg1a1D3cl"
      },
      "source": [
        "# <a id=\"5\">Model</a>\n",
        "\n",
        "We start with preparing the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "10b920b2ffc5de4a3ddebe494966d90cca91ee95",
        "id": "vNmNmWUmD3cm"
      },
      "source": [
        "## <a id=\"51\">Prepare the model</a>\n",
        "\n",
        "## Data preprocessing\n",
        "\n",
        "First we will do a data preprocessing to prepare for the model.\n",
        "\n",
        "We reshape the columns  from (784) to (28,28,1). We also save label (target) feature as a separate vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "db4c308b9fb334a54b4c055b00d2a1fbcf77ab96",
        "id": "ynm79GlUD3cn"
      },
      "source": [
        "# data preprocessing\n",
        "def data_preprocessing(raw):\n",
        "    out_y = keras.utils.to_categorical(raw.label, NUM_CLASSES)\n",
        "    num_images = raw.shape[0]\n",
        "    x_as_array = raw.values[:,1:]\n",
        "    x_shaped_array = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
        "    out_x = x_shaped_array / 255\n",
        "    return out_x, out_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2d3cafa55173d40cd9a42df63d4919f03b264c09",
        "id": "J44Iyeq4D3cu"
      },
      "source": [
        "We process both the train_data and the test_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "454d7a8fdca4bdbefc04a9d796de04b6af4a1767",
        "id": "FcKlRIQlD3cv"
      },
      "source": [
        "# prepare the data\n",
        "X, y = data_preprocessing(train_data)\n",
        "X_test, y_test = data_preprocessing(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8e25c569f0a0e817ca0462f3e3ea2f50feb480b0",
        "id": "2Teg36UeD3dq"
      },
      "source": [
        "## Split train in train and validation set\n",
        "\n",
        "We further split the train set in train and validation set. The validation set will be 20% from the original train set, therefore the split will be train/validation of 0.8/0.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "36eb910dd0868a227a73c9759d6aee0a47ba2b1e",
        "id": "5m0oYPu6D3dt"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1e623ca7c0c61634c0e4b890fc5cf5cacb132552",
        "id": "WoKTFixlD3d5"
      },
      "source": [
        "The dimmension of the processed train, validation and test set are as following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "98b3f1bf07e8ed614bf32b8e1955cbe90bff21c5",
        "id": "a12V1DmbD3d9"
      },
      "source": [
        "print(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\n",
        "print(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])\n",
        "print(\"Fashion MNIST test -  rows:\",X_test.shape[0],\" columns:\", X_test.shape[1:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5bc44b14e07efcd3dda90deaac6884b07285b484",
        "id": "fQQGXRRID3eH"
      },
      "source": [
        "Let's check the class inbalance for the rsulted training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a8c4e101cbbe68984f525e00afa8c7b7d8cc2215",
        "id": "MADxOWSQD3eJ"
      },
      "source": [
        "def plot_count_per_class(yd):\n",
        "    ydf = pd.DataFrame(yd)\n",
        "    f, ax = plt.subplots(1,1, figsize=(12,4))\n",
        "    g = sns.countplot(ydf[0], order = np.arange(0,10))\n",
        "    g.set_title(\"Number of items for each class\")\n",
        "    g.set_xlabel(\"Category\")\n",
        "    \n",
        "    for p, label in zip(g.patches, np.arange(0,10)):\n",
        "        g.annotate(labels[label], (p.get_x(), p.get_height()+0.1))\n",
        "        \n",
        "    plt.show()  \n",
        "\n",
        "def get_count_per_class(yd):\n",
        "    ydf = pd.DataFrame(yd)\n",
        "    # Get the count for each label\n",
        "    label_counts = ydf[0].value_counts()\n",
        "\n",
        "    # Get total number of samples\n",
        "    total_samples = len(yd)\n",
        "\n",
        "\n",
        "    # Count the number of items in each class\n",
        "    for i in range(len(label_counts)):\n",
        "        label = labels[label_counts.index[i]]\n",
        "        count = label_counts.values[i]\n",
        "        percent = (count / total_samples) * 100\n",
        "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
        "    \n",
        "plot_count_per_class(np.argmax(y_train,axis=1))\n",
        "get_count_per_class(np.argmax(y_train,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "07bfe3d5d50b985788a28e546473fd885d96dcef",
        "id": "8FAFN96XD3eO"
      },
      "source": [
        "And, as well, for the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "af3b3d31c42637235bc07b700db121e37e156afc",
        "id": "WwQeb8PvD3eQ"
      },
      "source": [
        "plot_count_per_class(np.argmax(y_val,axis=1))\n",
        "get_count_per_class(np.argmax(y_val,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "315162ff857021131d4ac6739bda800acc5c6c4b",
        "id": "gp_UwXutD3eX"
      },
      "source": [
        "Both the train and validation set are unbalanced with respect of distribution of classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dd9405b5a3fe0c7bd5bebe0616190a8cf26d2811",
        "id": "3zvx4eTBD3ee"
      },
      "source": [
        "## <a id=\"52\">Train the model</a>\n",
        "\n",
        "### Build the model   \n",
        "\n",
        "\n",
        "\n",
        "We will use a **Sequential** model.\n",
        "* The **Sequential** model is a linear stack of layers. It can be first initialized and then we add layers using **add** method or we can add all layers at init stage. The layers added are as follows:\n",
        "\n",
        "* **Conv2D** is a 2D Convolutional layer (i.e. spatial convolution over images). The parameters used are:\n",
        " * filters - the number of filters (Kernels) used with this layer; here filters = 32;\n",
        " * kernel_size - the dimmension of the Kernel: (3 x 3);\n",
        " * activation - is the activation function used, in this case `relu`;\n",
        " * kernel_initializer - the function used for initializing the kernel;\n",
        " * input_shape - is the shape of the image presented to the CNN: in our case is 28 x 28\n",
        " The input and output of the **Conv2D** is a 4D tensor.\n",
        " \n",
        "* **MaxPooling2D** is a Max pooling operation for spatial data. Parameters used here are:\n",
        " * *pool_size*, in this case (2,2), representing the factors by which to downscale in both directions;\n",
        " \n",
        " * **Conv2D** with the following parameters:\n",
        " * filters: 64;\n",
        " * kernel_size : (3 x 3);\n",
        " * activation : `relu`;\n",
        " \n",
        "* **MaxPooling2D** with parameter:\n",
        " * *pool_size* : (2,2);\n",
        "\n",
        "* **Conv2D** with the following parameters:\n",
        " * filters: 128;\n",
        " * kernel_size : (3 x 3);\n",
        " * activation : `relu`;\n",
        " \n",
        "* **Flatten**. This layer Flattens the input. Does not affect the batch size. It is used without parameters;\n",
        "\n",
        "* **Dense**. This layer is a regular fully-connected NN layer. It is used without parameters;\n",
        " * units - this is a positive integer, with the meaning: dimensionality of the output space; in this case is: 128;\n",
        " * activation - activation function : `relu`;\n",
        " \n",
        "* **Dense**. This is the final layer (fully connected). It is used with the parameters:\n",
        " * units: the number of classes (in our case 10);\n",
        " * activation : `softmax`; for this final layer it is used `softmax` activation (standard for multiclass classification)\n",
        " \n",
        "\n",
        "Then we compile the model, specifying as well the following parameters:\n",
        "* *loss*;\n",
        "* *optimizer*;\n",
        "* *metrics*. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e31836cd5ec9d86340485404b8f613d1f574aca4",
        "trusted": true,
        "id": "yohRSJOkD3ef"
      },
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ecb450d70539a62fb310bb7ed44849d2d01481ee",
        "id": "h-I0jCLqD3eu"
      },
      "source": [
        "### Inspect the model\n",
        "\n",
        "Let's check the model we initialized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b4b923b11ceaf4a97677f8e24265e3e97ae1653b",
        "scrolled": true,
        "trusted": true,
        "id": "cW4Dur3gD3ey"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "47062fcbe61fdc131bdc369428415c483167d046",
        "id": "An_cbKoID3e-"
      },
      "source": [
        "Let's also plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a9863ccbdc1a3f9d03fc6f3dbbd3f2713995d03e",
        "id": "JkU5evM6D3fA"
      },
      "source": [
        "plot_model(model, to_file='model.png')\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "68a2e932241f29e52a3150b3fcf3fe9c21243be2",
        "id": "bxEiWvWcD3fR"
      },
      "source": [
        "### Run the model\n",
        "\n",
        "We run the model with the training set. We are also using the validation set (a subset from the orginal training set) for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "400494b7e0525069175625422e8c300bd7b41c51",
        "scrolled": true,
        "trusted": true,
        "id": "YwCHHU3cD3fU"
      },
      "source": [
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8346a686cce7c75ab6d3c1f496aaa25b8a2f96d7",
        "id": "fkCQmTkpD3gH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8699df44bc0a95f1a43a201d3dd566746d87173f",
        "id": "qtHBMAhKD3gS"
      },
      "source": [
        "## <a id=\"53\">Test prediction accuracy</a>\n",
        "\n",
        "We calculate the test loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b9e2bb7f25b02d491e34dd0d6d05943e287ae369",
        "trusted": true,
        "id": "PqGyALN_D3gU"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "4d779b0e47b8263370031c292a231b69decad374",
        "id": "wTrd5aQDD3gj"
      },
      "source": [
        "Test accuracy is  around  0.91.\n",
        "\n",
        "We evaluated the model accuracy based on the predicted values for the test set.  Let's check the validation value during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2b08e362a264d65687c49919f477e5d11c84d658",
        "id": "nGpLnZb1D3gk"
      },
      "source": [
        "## <a id=\"53\">Validation accuracy and loss</a>\n",
        "\n",
        "Let's plot the train and validation accuracy and loss, from the train history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "c034e2f70f0a26f453a764cd3dc6bbdebb3c4c53",
        "id": "yYoz0TpoD3gu"
      },
      "source": [
        "def create_trace(x,y,ylabel,color):\n",
        "        trace = go.Scatter(\n",
        "            x = x,y = y,\n",
        "            name=ylabel,\n",
        "            marker=dict(color=color),\n",
        "            mode = \"markers+lines\",\n",
        "            text=x\n",
        "        )\n",
        "        return trace\n",
        "    \n",
        "def plot_accuracy_and_loss(train_model):\n",
        "    hist = train_model.history\n",
        "    acc = hist['acc']\n",
        "    val_acc = hist['val_acc']\n",
        "    loss = hist['loss']\n",
        "    val_loss = hist['val_loss']\n",
        "    epochs = list(range(1,len(acc)+1))\n",
        "    \n",
        "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
        "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
        "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
        "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
        "   \n",
        "    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
        "                                                             'Training and validation loss'))\n",
        "    fig.append_trace(trace_ta,1,1)\n",
        "    fig.append_trace(trace_va,1,1)\n",
        "    fig.append_trace(trace_tl,1,2)\n",
        "    fig.append_trace(trace_vl,1,2)\n",
        "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
        "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
        "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
        "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
        "\n",
        "    \n",
        "    iplot(fig, filename='accuracy-loss')\n",
        "\n",
        "plot_accuracy_and_loss(train_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "678f32a0980699b8aa41a3f98840bcc1eabb2aa8",
        "id": "Rzh9JtSkD3hH"
      },
      "source": [
        "The validation accuracy does not improve after few epochs and the validation loss is increasing after few epochs. This confirms our assumption that the model is overfitted. We will try to improve the model by adding Dropout layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5c026022d95d3afefc3e2cf47050c3db5f800ee1",
        "id": "pilKm6BpD3hd"
      },
      "source": [
        "## <a id=\"55\">Add Dropout layers to the model</a>\n",
        "\n",
        "We add several Dropout layers to the model, to help avoiding overfitting.    \n",
        "Dropout is helping avoid overfitting in several ways, as explained in <a href='#8'>[6]</a> and <a href='#8'>[7]</a>.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6aff87cd33a993a60d701c35026ce8ea19d8665a",
        "id": "IIVhJXipD3he"
      },
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Add dropouts to the model\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "46811947e60224235b1ffaed48e7367b3ba68833",
        "id": "dQ1e5a1gD3hl"
      },
      "source": [
        "## <a id=\"56\">Re-train the model</a>\n",
        "\n",
        "Let's inspect first the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "594c8f00280db3fd6d4719791326d73c4769117d",
        "id": "ZvsVKhX1D3hq"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ab0eb83773ab435204faef8c88b609a29feb635e",
        "id": "V47N_wyZD3hx"
      },
      "source": [
        "Let's also plot the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6abc11f358fb81d2655f80bea7762546b18dee82",
        "id": "LdG0tby3D3hy"
      },
      "source": [
        "plot_model(model, to_file='model.png')\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "99a964cc1478f1a8583e803ad7eeb35aadd15995",
        "id": "LPzmbrnxD3iE"
      },
      "source": [
        "And now let's run the new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "83029bfb27f99fb6be2ecedc1bd256c0e861456c",
        "id": "CaTywOmZD3iG"
      },
      "source": [
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "676e1c4a3a64db55d6f0e8498f9c59e0e6182931",
        "id": "4s-FFmcdD3nF"
      },
      "source": [
        "## <a id=\"57\">Prediction accuracy with the new model</a>\n",
        "\n",
        "Let's re-evaluate the prediction accuracy with the new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6b3940059502bfb6303a85a2cee1095b45304491",
        "id": "iXNfqNMBD3nH"
      },
      "source": [
        "plot_accuracy_and_loss(train_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f201d6925f70ad2420b3ee7e3a204cdc77f86723",
        "id": "kE5ZAdoFD3p5"
      },
      "source": [
        "After adding the Dropout layers, the validation accuracy and validation loss are much better. Let's check now the prediction for the test set.\n",
        "\n",
        "\n",
        "## <a id=\"58\">Prediction accuracy with the new model</a>\n",
        "\n",
        "Let's re-evaluate the test prediction accuracy with the new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d8e9293e99e34010bd456af7435c4cc7ccebdefd",
        "id": "9y7sRtAOD3p6"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "572baa4ad0f12f490337137f7f9fb56a8a9a48c6",
        "id": "jPluKS5dD3qM"
      },
      "source": [
        "Also the test accuracy improved. The test accuracy is now approximately 0.93."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e519f82cc29b0dd8c5145d612da3eb496e2b321d",
        "trusted": true,
        "id": "x6NbLUqoD3qQ"
      },
      "source": [
        "#get the predictions for the test data\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "#get the indices to be plotted\n",
        "y_true = test_data.iloc[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d5989dd811570fe73b1f6b0715b06c428e578669",
        "id": "RVhsQ3W-D3qk"
      },
      "source": [
        "p = predicted_classes[:10000]\n",
        "y = y_true[:10000]\n",
        "correct = np.nonzero(p==y)[0]\n",
        "incorrect = np.nonzero(p!=y)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "46acb309f135a4082b4e1cd9b98a613b888f7c7e",
        "id": "p9ub4FAkD3qw"
      },
      "source": [
        "print(\"Correct predicted classes:\",correct.shape[0])\n",
        "print(\"Incorrect predicted classes:\",incorrect.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "bc3bfd05450aaee55c9e5edc7fb84d884c1d3e0b",
        "id": "ZeYG6AaJD3q7"
      },
      "source": [
        "target_names = [\"Class {} ({}) :\".format(i,labels[i]) for i in range(NUM_CLASSES)]\n",
        "print(classification_report(y_true, predicted_classes, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "4b0b88588bd3afed148a3c696d997aea4a6c564a",
        "id": "Jh58NcbaD3uw"
      },
      "source": [
        "\n",
        "The best accuracy is obtained for Class 1, Class 5, Class 8, Class 9  and Class 7. Worst accuracy is for Class 6.   \n",
        "\n",
        "The recall is highest for Class 8, Class 5 and smallest for Class 6 and Class 4.    \n",
        "\n",
        "f1-score is highest for Class 1, Class 5 and Class 8 and smallest for Class 6 followed by Class 4 and Class 2.  \n",
        "\n",
        "Let's also inspect some of the images. We created two subsets of the predicted images set, correctly and incorrectly classified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "614afbc7ed760856cf9b47f879334902d1b6545b",
        "id": "PMQiDr9oD3u6"
      },
      "source": [
        "# <a id=\"6\">Visualize classified images</a>\n",
        "\n",
        "## <a id=\"61\">Correctly classified images</a>\n",
        "\n",
        "\n",
        "We visualize few images correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "e64edf6e7ae3146eafe8da01f4dbc4e05c8bc1ce",
        "id": "4gwLVZOrD3u8"
      },
      "source": [
        "def plot_images(data_index,cmap=\"Blues\"):\n",
        "    # Plot the sample images now\n",
        "    f, ax = plt.subplots(4,4, figsize=(15,15))\n",
        "\n",
        "    for i, indx in enumerate(data_index[:16]):\n",
        "        ax[i//4, i%4].imshow(X_test[indx].reshape(IMG_ROWS,IMG_COLS), cmap=cmap)\n",
        "        ax[i//4, i%4].axis('off')\n",
        "        ax[i//4, i%4].set_title(\"True:{}  Pred:{}\".format(labels[y_true[indx]],labels[predicted_classes[indx]]))\n",
        "    plt.show()    \n",
        "    \n",
        "plot_images(correct, \"Greens\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3c7bb1b300a4530d2fa418eb56258a54587e3b90",
        "id": "JtaFGwPDD3vS"
      },
      "source": [
        "## <a id=\"62\">Incorrectly classified images</a>\n",
        "\n",
        "Let's see also few images incorrectly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "18b2843f6f8542cd95d0847617e84e959996341b",
        "id": "Vmx2kElMD3vT"
      },
      "source": [
        "plot_images(incorrect, \"Reds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e24053db4dbfec25fd1b90391586d7ce6bc32988",
        "id": "Aazwg-3wD3vm"
      },
      "source": [
        "# <a id=\"7\">Conclusions</a>\n",
        "\n",
        "With a complex sequential model with multiple convolution layers and 50 epochs for the training, we obtained an accuracy ~0.91 for test prediction.\n",
        "After investigating the validation accuracy and loss, we understood that the model is overfitting.   \n",
        "We retrained the model with Dropout layers to the model to reduce overfitting.  \n",
        "We confirmed the model improvement and with the same number of epochs for the training we obtained with the new model an accuracy of ~0.93 for test prediction. Only few classes are not correctly classified all the time, especially Class 6 (Shirt) and Class 2 (Pullover)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1b45e3422fb9507da66ce7af67a97b54e7fa7683",
        "id": "71mNB_0GD3vo"
      },
      "source": [
        "# <a id=\"8\">References</a>\n",
        "\n",
        "[1] Fashion MNIST, An MNIST-like dataset of 70,000 28x28 labeled fashion images, https://www.kaggle.com/zalando-research/fashionmnist  \n",
        "[2] DanB, CollinMoris, Deep Learning From Scratch, https://www.kaggle.com/dansbecker/deep-learning-from-scratch  \n",
        "[3] DanB, Dropout and Strides for Larger Models, https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models  \n",
        "[4] BGO, CNN with Keras, https://www.kaggle.com/bugraokcu/cnn-with-keras    \n",
        "[5] NAIN, EagerFMINST, https://www.kaggle.com/aakashnain/eagerfmnist  \n",
        "[6] Why Dropounts prevent overfitting in Deep Neural Networks, https://medium.com/@vivek.yadav/why-dropouts-prevent-overfitting-in-deep-neural-networks-937e2543a701  \n",
        "[7] Dropout: A Simple Way to Prevent Neural Networks from Overfitting, https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf  "
      ]
    }
  ]
}